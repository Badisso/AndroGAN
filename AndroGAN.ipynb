{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "usKjRN4BaKe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6da4401-bdb1-4877-e874-1d79925d701c"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from tensorflow.python.keras.backend import get_session\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from numpy import hstack\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import rand\n",
        "from numpy.random import randn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "import keras\n",
        "import tensorflow\n",
        "batch = 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD0tJ-0DXSvc",
        "outputId": "050af01b-80ba-4782-a3e3-247afd724f9d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VatUiYwfxxec"
      },
      "source": [
        "@tf.function\n",
        "def custom_activation(x):\n",
        "   global batch\n",
        "   return tf.where(tf.less_equal(x, 0.5),tf.ones((32,7684)),tf.zeros((32,7684)))\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72jjDgKbyRbo"
      },
      "source": [
        "def define_discriminator(n_inputs=7684):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(7684,activation=\"relu\",input_dim=7684))\n",
        "  model.add(Dense(200,activation=\"sigmoid\"))\n",
        "  model.add(Dense(200,activation=\"relu\"))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(\n",
        "  optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy'],\n",
        "  )\n",
        "  model.load_weights(\"/content/drive/MyDrive/dataset master/model1.h5\")\n",
        "\t#model =  tensorflow.keras.models.load_model(\"/content/drive/MyDrive/dataset master/model.h5\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC9pvm3AyM3u"
      },
      "source": [
        "def define_generator(latent_dim, n_outputs=7684):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(7684, activation=\"relu\",input_dim=7684))\n",
        "  model.add(Dense(3000,activation=\"softmax\"))\n",
        "  model.add(Dense(200,activation=\"tanh\"))\n",
        "  model.add(Dense(7684, activation='sigmoid'))\n",
        "  model.compile(\n",
        "  optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy'],\n",
        "  )\n",
        "  #model.add(Activation(custom_activation, name='SpecialActivation'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTu2kIQXyWiB"
      },
      "source": [
        "def define_gan(generator, discriminator):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tdiscriminator.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(discriminator)\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnzYS3d7yetT"
      },
      "source": [
        "def generate_real_samples(n):\n",
        "  dataset = pd.read_csv(\"/content/drive/MyDrive/dataset master/benign.csv\",skiprows=0,nrows=n).fillna(0)\n",
        "  X = dataset.drop(\"40\",axis=1)\n",
        "  X = X.to_numpy()\n",
        "\t# generate class labels\n",
        "  y = zeros((n, 1))\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgKCDXOexQnU"
      },
      "source": [
        "def generate_real_samples_for_evaluation(n):\n",
        "  dataset = pd.read_csv(\"/content/drive/MyDrive/dataset master/benign.csv\",skiprows=5344,nrows=n).fillna(0)\n",
        "  X = dataset.drop(\"10\",axis=1)\n",
        "  X = X.to_numpy()\n",
        "\t# generate class labels\n",
        "  y = zeros((n, 1))\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15vVgUuDyiMR"
      },
      "source": [
        "def generate_latent_points(latent_dim, n):\n",
        "  dataset = pd.read_csv(\"/content/drive/MyDrive/dataset master/malware.csv\",skiprows=0,nrows=n).fillna(0)\n",
        "  X = dataset.drop(\"100\",axis=1)\n",
        "  X = X.to_numpy()\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l69F2YVRxC7a"
      },
      "source": [
        "def generate_latent_points_for_evaluation(latent_dim, n):\n",
        "  dataset = pd.read_csv(\"/content/drive/MyDrive/dataset master/malware.csv\",skiprows=5344,nrows=n).fillna(0)\n",
        "  X = dataset.drop(\"100\",axis=1)\n",
        "  X = X.to_numpy()\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjvBQgB_ysoe"
      },
      "source": [
        "def generate_fake_samples(generator, latent_dim, n):\n",
        "  global batch\n",
        "  # generate points in latent space\n",
        "  x_input = generate_latent_points(latent_dim, n)\n",
        "  # predict outputs\n",
        "  X = generator.predict(x_input)\n",
        "  for i in range(len(X)):\n",
        "    for j in range(7684):\n",
        "      if X[i][j] < 0.5 and x_input[i][j] == 1:\n",
        "          X[i][j] = 1\n",
        "      elif X[i][j] < 0.5 and x_input[i][j] == 0:\n",
        "          X[i][j] = 0\n",
        "      elif X[i][j] > 0.5:\n",
        "          X[i][j] = 1\n",
        "  # create class labels\n",
        "  y = ones((len(X), 1))\n",
        "  batch = len(X)\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7jtS1cwwmjX"
      },
      "source": [
        "def generate_fake_samples_for_evaluation(generator, latent_dim, n = 1344):\n",
        "  global batch\n",
        "  # generate points in latent space\n",
        "  x_input = generate_latent_points_for_evaluation(latent_dim, n)\n",
        "  # predict outputs\n",
        "  X = generator.predict(x_input)\n",
        "  for i in range(len(X)):\n",
        "    for j in range(7684):\n",
        "      if X[i][j] < 0.5 and x_input[i][j] == 1:\n",
        "          X[i][j] = 1\n",
        "      elif X[i][j] < 0.5 and x_input[i][j] == 0:\n",
        "          X[i][j] = 0\n",
        "      elif X[i][j] > 0.5:\n",
        "          X[i][j] = 1\n",
        "\n",
        "  # create class labels\n",
        "  y = ones((len(X), 1))\n",
        "  batch = len(X)\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY07xP3XzWdT"
      },
      "source": [
        "def summarize_performance(epoch, generator, discriminator, latent_dim, n=1344):\n",
        "\t# prepare real samples\n",
        "  x_real, y_real = generate_real_samples_for_evaluation(n)\n",
        "\t# evaluate discriminator on real examples\n",
        "  _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "  x_fake, y_fake = generate_fake_samples_for_evaluation(generator, latent_dim, n)\n",
        "\t# evaluate discriminator on fake examples\n",
        "  _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
        "  # summarize discriminator performance\n",
        "  generator.save(\"model.h5\")\n",
        "  print(\"epoch : \"+str(epoch)+\"acc_real : \"+str(acc_real)+\"acc_fake : \"+str(acc_fake))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cS3fWjGzZja"
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, latent_dim, n_epochs=10000, n_batch=2048, n_eval=2000):\n",
        "\t# determine half the size of one batch, for updating the discriminator\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# prepare real samples\n",
        "\t\tx_real, y_real = generate_real_samples(half_batch)\n",
        "\t\t# prepare fake examples\n",
        "\t\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\n",
        "    # update discriminator\n",
        "\t\td_model.train_on_batch(x_real, y_real)\n",
        "\t\td_model.train_on_batch(x_fake, y_fake)\n",
        "\n",
        "    # prepare points in latent space as input for the generator\n",
        "\t\tx_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# create inverted labels for the fake samples\n",
        "\t\ty_gan = zeros((n_batch, 1))\n",
        "\t\t# update the generator via the discriminator's error\n",
        "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
        "\t\t# evaluate the model every n_eval epochs\n",
        "\t\tif (i+1) % n_eval == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBrI4GrjznT2"
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 7684\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# train model\n",
        "train(generator, discriminator, gan_model, latent_dim,n_epochs=10,n_eval=1,n_batch=10688)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCOwv4lO0BYi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDHoCXC87JOb"
      },
      "source": [
        "  ## TEST GENERATOR ##\n",
        "  Gmodel = Sequential()\n",
        "  Gmodel.add(Dense(7684, activation=\"relu\",input_dim=7684))\n",
        "  Gmodel.add(Dense(3000,activation=\"softmax\"))\n",
        "  Gmodel.add(Dense(200,activation=\"tanh\"))\n",
        "  Gmodel.add(Dense(7684, activation='sigmoid'))\n",
        "  Gmodel.compile(\n",
        "  optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy'],\n",
        "  )\n",
        "  Gmodel.load_weights(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-412X2E7zhF"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(7684,activation=\"relu\",input_dim=7684))\n",
        "model.add(Dense(200,activation=\"sigmoid\"))\n",
        "model.add(Dense(200,activation=\"relu\"))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(\n",
        "optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy'],\n",
        ")\n",
        "model.load_weights(\"/content/drive/MyDrive/dataset master/model1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqw5ZdBZ8LwP"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/dataset master/malware.csv\",skiprows=5344).fillna(0)\n",
        "X = dataset.drop(\"100\",axis=1)\n",
        "X = X.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__OaqhOG8KF8"
      },
      "source": [
        "prediction = model.predict(X)\n",
        "y_pred = np.argmax(prediction, axis=1)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5LP1NXI9QJw"
      },
      "source": [
        "generated = Gmodel.predict(X)\n",
        "for i in range(len(X)):\n",
        "    for j in range(7684):\n",
        "      if generated[i][j] < 0.5 and X[i][j] == 1:\n",
        "          generated[i][j] = 1\n",
        "      elif generated[i][j] < 0.5 and X[i][j] == 0:\n",
        "          generated[i][j] = 0\n",
        "      elif generated[i][j] > 0.5:\n",
        "          generated[i][j] = 1\n",
        "\n",
        "Generated_predection = model.predict(generated)\n",
        "y_predG = np.argmax(Generated_predection, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxAf3bGyAD1T"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_pred, y_predG))\n",
        "print(confusion_matrix(y_pred, y_predG))\n",
        "print(classification_report(y_pred, y_predG))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igLIiafiDAMS"
      },
      "source": [
        "print(accuracy_score(y_pred, np.ones((len(y_pred),1))))\n",
        "print(confusion_matrix(y_pred,  np.ones((len(y_pred),1))))\n",
        "print(classification_report(y_pred,  np.ones((len(y_pred),1))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "236MtyhzXb68"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/dataset master/malware.csv\").fillna(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pl_6nZKXsPC"
      },
      "source": [
        "y = dataset[\"100\"]\n",
        "X = dataset.drop(\"100\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umO0TIqsr62V"
      },
      "source": [
        "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=0.0001)\n",
        "train_images = train_images.to_numpy()\n",
        "test_images = test_images.to_numpy()\n",
        "batch = len(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpyqsI6hX2AC"
      },
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkvhdbhgguPk"
      },
      "source": [
        "zero = 0\n",
        "un = 0\n",
        "prediction = model.predict(test_images)[1]\n",
        "for i in range(7684):\n",
        "  if prediction[i] == test_images[1][i]:\n",
        "     zero = zero + 1\n",
        "  else:\n",
        "    un = un + 1\n",
        "print(zero)\n",
        "print(un)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVpKz6lRjWZK"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(7684, activation = 'sigmoid',input_dim=7684))\n",
        "model.add(MyCustomLayer(32, input_shape = (7684,)))\n",
        "\n",
        "model.summary()\n",
        "print(model.predict(X)[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}